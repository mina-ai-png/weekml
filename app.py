# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12TfmFh4EgQGnhF8mW7OjzqdgLvBws8HG
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import streamlit as st

# Step 1: Load and explore the dataset
# Use the correct path to your local dataset
data = pd.read_csv(r'C:\Users\MANAHIL\Documents\Ml\WA_Fn-UseC_-Telco-Customer-Churn.csv')

# Display the first few rows of the dataset
st.write("Dataset Preview:")
st.write(data.head())

# Step 2: Data Preprocessing
# Remove unnecessary columns
data.drop(['customerID'], axis=1, inplace=True)

# Handle missing values
data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')

# Separate numeric and non-numeric columns
numeric_cols = data.select_dtypes(include=[np.number]).columns
non_numeric_cols = data.select_dtypes(exclude=[np.number]).columns

# Fill missing values for numeric columns with mean
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())

# Fill missing values for non-numeric columns with the mode (most frequent value)
for column in non_numeric_cols:
    data[column] = data[column].fillna(data[column].mode()[0])

# Encode categorical variables
for column in data.columns:
    if data[column].dtype == object:
        data[column] = LabelEncoder().fit_transform(data[column])

# Feature and target selection
X = data.drop('Churn', axis=1)
y = data['Churn']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 3: Model Building
# Initialize the Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Step 4: Model Evaluation
y_pred = model.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Display evaluation metrics
st.write("Model Evaluation Metrics:")
st.write(f"Accuracy: {accuracy}")
st.write(f"Precision: {precision}")
st.write(f"Recall: {recall}")
st.write(f"F1-Score: {f1}")

# Step 5: Model Deployment with Streamlit
st.title("Customer Churn Prediction")

# Inputs for prediction
tenure = st.number_input("Tenure", min_value=0, max_value=100, value=0)
monthly_charges = st.number_input("Monthly Charges", min_value=0.0, max_value=1000.0, value=0.0)
total_charges = st.number_input("Total Charges", min_value=0.0, max_value=10000.0, value=0.0)

# Create a button for prediction
if st.button("Predict Churn"):
    # Preprocess input data
    input_data = scaler.transform([[tenure, monthly_charges, total_charges]])

    # Predict churn
    prediction = model.predict(input_data)

    # Display the result
    churn_status = "Churn" if prediction[0] == 1 else "No Churn"
    st.write(f"The predicted churn status is: {churn_status}")

# Run the Streamlit app by saving the code into a file named `app.py` and executing:
# streamlit run app.py

